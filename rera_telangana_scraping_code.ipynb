{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "url = \"http://rerait.telangana.gov.in/SearchList/Search\"\n",
    "from selenium import webdriver\n",
    "def driver_call(url):\n",
    "        global driver\n",
    "        #System.setProperty(\"webdriver.chrome.driver\",\"/usr/bin/chromedriver\");\n",
    "        driver = webdriver.Chrome(executable_path=\"/home/anm/Downloads/chromedriver_linux64 (2)/chromedriver\")\n",
    "        #driver= webdriver.Chrome(executable_path=\"/home/anm/Downloads/chromedriver_linux64/chromedriver\")\n",
    "        driver.get(url)\n",
    "        time.sleep(8)\n",
    "def get_all_tables(soup):\n",
    "    \"\"\"Extracts and returns all tables in a soup object\"\"\"\n",
    "    return soup.find_all(\"table\")\n",
    "def get_all_tables(soup):\n",
    "    \"\"\"Extracts and returns all tables in a soup object\"\"\"\n",
    "    return soup.find_all(\"table\")\n",
    "def get_table_headers(table):\n",
    "    \"\"\"Given a table soup, returns all the headers\"\"\"\n",
    "    headers = []\n",
    "    for th in table.find(\"tr\").find_all(\"th\"):\n",
    "        headers.append(th.text.strip())\n",
    "    return headers\n",
    "def get_table_rows(table):\n",
    "    \"\"\"Given a table, returns all its rows\"\"\"\n",
    "    rows = []\n",
    "    for tr in table.find_all(\"tr\")[1:]:\n",
    "        cells = []\n",
    "        # grab all td tags in this table row\n",
    "        tds = tr.find_all(\"td\")\n",
    "        if len(tds) == 0:\n",
    "            # if no td tags, search for th tags\n",
    "            # can be found especially in wikipedia tables below the table\n",
    "            ths = tr.find_all(\"th\")\n",
    "            for th in ths:\n",
    "                cells.append(th.text.strip())\n",
    "        else:\n",
    "            # use regular td tags\n",
    "            for td in tds:\n",
    "                cells.append(td.text.strip())\n",
    "        rows.append(cells)\n",
    "    return rows\n",
    "def save_as_csv(table_name, headers, rows, writer):\n",
    "    #pd.DataFrame(rows, columns=headers).to_csv(f\"{table_name}.csv\")\n",
    "    # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "    #writer = pd.ExcelWriter('pandas_multiple.xlsx', engine='xlsxwriter')\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    # Write each dataframe to a different worksheet.\n",
    "    pd.DataFrame(rows, columns=headers).to_excel(writer, sheet_name=\"{}\".format(table_name))\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "    \n",
    "def save_as_csv_dummy(writer, table_name):\n",
    "    \n",
    "    # Write each dataframe to a different worksheet.\n",
    "    pd.DataFrame().to_excel(writer, sheet_name=\"{}\".format(table_name))\n",
    "    writer.save()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 1\n",
    "i=1\n",
    "page=1\n",
    "driver_call(url)\n",
    "Project_approved = []           \n",
    "Project_details = []\n",
    "Project_details_list = []\n",
    "\n",
    "while(i<12):\n",
    "    \n",
    "    print(\"\")\n",
    "    \n",
    "    \n",
    "    if i==11:\n",
    "\n",
    "        i=1\n",
    "        print(\"row\",i)\n",
    "        page = page + 1\n",
    "        \n",
    "        print(\"page\",page)\n",
    "        if page==218:\n",
    "            i=12\n",
    "\n",
    "    else:\n",
    "        \n",
    "        if page > 1:\n",
    "            if i==1:\n",
    "                elementID=driver.find_element_by_xpath('//*[@id=\"btnNext\"]')\n",
    "                elementID.click()\n",
    "                time.sleep(15)\n",
    "#'//*[@id=\"onlineregisteredproject\"]/tr['+str(i)+']/td[7]/a'\n",
    "        wait = WebDriverWait(driver,10)\n",
    "        try:\n",
    "            wait.until(EC.element_to_be_clickable((By.XPATH,'//*[@id=\"gridview\"]/div[1]/div/table/tbody/tr['+str(i)+']/td[5]/a' ))).click()\n",
    "        except TimeoutException:\n",
    "            pass\n",
    "        #elementID=driver.find_element_by_xpath('//*[@id=\"gridview\"]/div[1]/div/table/tbody/tr['+str(i)+']/td[5]/a')\n",
    "       # elementID.click()\n",
    "        time.sleep(10)\n",
    "        driver.switch_to.window(driver.window_handles[-1])\n",
    "        Project_approved.append(driver.page_source)\n",
    "        time.sleep(10)\n",
    "        Project_name=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[2]/div/div[2]').text\n",
    "        print(Project_name)\n",
    "        Project_status = driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[2]/div/div[4]').text\n",
    "        Approval_date=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[3]/div/div[2]').text\n",
    "        Proposed_date_completion=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[4]/div/div[2]').text\n",
    "        #Revise_pro_com=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[4]/div/div[4]').text\n",
    "        Project_type =driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[1]/div/div[4]').text\n",
    "        Letigation=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[1]/div/div[2]').text\n",
    "        Promoter=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[2]/div/div[2]').text\n",
    "        Sy_no=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[4]/div/div[2]').text\n",
    "        Plot_house_no=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[4]/div/div[4]').text\n",
    "        Total_area=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[5]/div/div[2]').text\n",
    "        Area_Afected_road_widen=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[5]/div/div[4]').text\n",
    "        Net_area=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[6]/div/div[2]').text\n",
    "        Total_building_unit=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[6]/div/div[4]').text\n",
    "        Proposed_building_unit=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[7]/div/div[2]').text\n",
    "        Approved_build_up_area=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[12]/div/div[2]').text\n",
    "        Mortgage_area=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[12]/div/div[3]/div[2]').text\n",
    "        State=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[15]/div/div[2]').text\n",
    "        District=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[15]/div/div[4]').text\n",
    "        Mandal=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[16]/div/div[2]').text\n",
    "        Village=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[16]/div/div[4]').text\n",
    "        Street=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[17]/div[1]/div[2]').text\n",
    "        Locality=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[17]/div[1]/div[4]').text\n",
    "        Pincode=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[7]/div/div[2]').text\n",
    "        Authority_name=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[1]/div/div[2]').text\n",
    "        Plan_approval_no=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[1]/div/div[4]').text\n",
    "        soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        TARGET_DIR = f'/home/anm/rera_telangana/demo/'\n",
    "\n",
    "        id_list = [\"DivExp\",\"DivAmenities\", \"DivBuilding\", \"DivProfessional\"]\n",
    "\n",
    "        #soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        #file = 1\n",
    "        # iterate over all tables\n",
    "        filepath = \"{}Project_{}.xlsx\".format(TARGET_DIR,file)\n",
    "        wb = openpyxl.Workbook()\n",
    "        wb.save(filepath)\n",
    "        print(filepath)\n",
    "\n",
    "        print(\"Created excel file Project_{}.xlsx\".format(file))\n",
    "\n",
    "        for il in range(len(id_list)):\n",
    "\n",
    "            table_topic_list = []\n",
    "            print(id_list[il])\n",
    "\n",
    "\n",
    "            table_header = soup.find(\"div\", id = id_list[il]).select(\"h2\")\n",
    "            #table.select(\"h2\")\n",
    "\n",
    "            if(len(table_header) > 0):\n",
    "                for j in range(len(table_header)):\n",
    "                    table_topic=table_header[j].text\n",
    "                    print(table_topic)\n",
    "                    table_topic_list.append(table_topic)\n",
    "            else: \n",
    "                print(\"No header\")\n",
    "                table_topic = 'NA'\n",
    "                table_topic_list.append(table_topic)\n",
    "\n",
    "\n",
    "            table_list = soup.find(\"div\", id = id_list[il]).select(\"table\")\n",
    "            #table.select(\"h2\")\n",
    "            #table_name=table_metaname[0].text\n",
    "            print(f\"[+] Found a total of {len(table_list)} tables.\")\n",
    "            if(len(table_list) > 0):\n",
    "\n",
    "                counter = 0\n",
    "\n",
    "                nested_table = []\n",
    "                in_tables = []\n",
    "\n",
    "                for t in table_list:\n",
    "                    nest = len(t.find_parents(\"table\"))\n",
    "                    if nest == 1:\n",
    "                        in_tables.append(t)\n",
    "                    nested_table.append(nest)\n",
    "\n",
    "\n",
    "                if all(v == 0 for v in nested_table):\n",
    "\n",
    "                    print(\"okay\")\n",
    "\n",
    "                    for num_table in range(len(table_list)):\n",
    "                        #try:\n",
    "                        # get the table headers\n",
    "                        headers = get_table_headers(table_list[num_table])\n",
    "                        # get all the rows of the table\n",
    "                        rows = get_table_rows(table_list[num_table])\n",
    "                        path = \"{}Project_{}.xlsx\".format(TARGET_DIR,file)\n",
    "                        book = load_workbook(path)\n",
    "                        writer = pd.ExcelWriter(path, engine = 'openpyxl')\n",
    "                        writer.book = book\n",
    "\n",
    "                        # save table as sheet\n",
    "                        table_name = table_topic_list[counter]\n",
    "                        counter = counter + 1\n",
    "                        print(f\"[+] Saving {table_name}\")\n",
    "                        print(headers)\n",
    "                        print(rows)\n",
    "                        save_as_csv(table_name, headers, rows, writer)\n",
    "\n",
    "                else:\n",
    "                    print(\"nested\")\n",
    "\n",
    "                    for num_table in range(len(in_tables)):\n",
    "\n",
    "                        if len(in_tables[num_table].find_parents(\"table\")) == 1:\n",
    "\n",
    "                            #try:\n",
    "                            # get the table headers\n",
    "                            headers = get_table_headers(in_tables[num_table])\n",
    "                            # get all the rows of the table\n",
    "                            rows = get_table_rows(in_tables[num_table])\n",
    "                            path = \"{}Project_{}.xlsx\".format(TARGET_DIR,file)\n",
    "                            book = load_workbook(path)\n",
    "                            writer = pd.ExcelWriter(path, engine = 'openpyxl')\n",
    "                            writer.book = book\n",
    "\n",
    "                            # save table as sheet\n",
    "                            table_name = table_topic_list[counter]\n",
    "                            #counter = counter + 1\n",
    "                            print(f\"[+] Saving {table_name}\")\n",
    "                            print(headers)\n",
    "                            print(rows)\n",
    "                            save_as_csv(table_name, headers, rows, writer)\n",
    "\n",
    "\n",
    "                    table = table_list[0]\n",
    "                    for tdcol in table.select('td[colspan]'):\n",
    "                        tdcol.parent.decompose()\n",
    "\n",
    "\n",
    "                    #try:\n",
    "                    # get the table headers\n",
    "                    headers = get_table_headers(table)\n",
    "                    # get all the rows of the table\n",
    "                    rows = get_table_rows(table)\n",
    "                    path = \"{}Project_{}.xlsx\".format(TARGET_DIR,file)\n",
    "                    book = load_workbook(path)\n",
    "                    writer = pd.ExcelWriter(path, engine = 'openpyxl')\n",
    "                    writer.book = book\n",
    "\n",
    "                    # save table as sheet\n",
    "                    table_name = table_topic_list[counter]\n",
    "                    #counter = counter + 1\n",
    "                    print(f\"[+] Saving {table_name}\")\n",
    "                    print(headers)\n",
    "                    print(rows)\n",
    "                    save_as_csv(table_name, headers, rows, writer)\n",
    "                #except:\n",
    "                    #print(\"fail\")\n",
    "                #print(table_name)\n",
    "\n",
    "        else: \n",
    "                counter = 0\n",
    "                print(\"No Table was found\")\n",
    "                table_name = table_topic_list[counter]\n",
    "                save_as_csv_dummy (writer, table_name)\n",
    "\n",
    "\n",
    "        file= file + 1\n",
    "            #table_metaname[0]\n",
    "\n",
    "        Project_details = [Project_name,Project_status,Approval_date,Proposed_date_completion,Project_type,\n",
    "                        Letigation,Promoter,Sy_no,Plot_house_no,Total_area,Area_Afected_road_widen,Net_area,Total_building_unit,\n",
    "                        Proposed_building_unit,Approved_build_up_area, Mortgage_area,State,District,Mandal,Village,Street,Locality,\n",
    "                           Pincode,Authority_name,Plan_approval_no]\n",
    "        Project_details_list.append(Project_details)\n",
    "\n",
    "        i=i+1\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "    \n",
    "Project_details_list_df = pd.DataFrame(Project_details_list,columns =['Project_name','Project_status','Approval_date','Proposed_date_completion','Project_type',\n",
    "                        'Letigation','Promoter','Sy_no','Plot_house_no','Total_area','Area_Afected_road_widen','Net_area','Total_building_unit',\n",
    "                        'Proposed_building_unit','Approved_build_up_area', 'Mortgage_area','State','District','Mandal','Village','Street','Locality',\n",
    "                           'Pincode','Authority_name','Plan_approval_no'])\n",
    "Project_details_list_df.to_csv(\"/home/anm/rera_telangana/reratelangna.csv\", index = False)\n",
    "print(\"Task Completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 1741\n",
    "i=1\n",
    "k=1\n",
    "page=1\n",
    "driver_call(url)\n",
    "Project_approved = []           \n",
    "Project_details = []\n",
    "Project_details_list = []\n",
    "for k in range(1,175):\n",
    "    elementID=driver.find_element_by_xpath('//*[@id=\"btnNext\"]')\n",
    "    elementID.click()\n",
    "\n",
    "while(i<12):\n",
    "    \n",
    "    print(\"\")\n",
    "    \n",
    "    \n",
    "    if i==11:\n",
    "\n",
    "        i=1\n",
    "        print(\"row\",i)\n",
    "        page = page + 1\n",
    "        \n",
    "        print(\"page\",page)\n",
    "        if page==218:\n",
    "            i=12\n",
    "\n",
    "    else:\n",
    "        \n",
    "        if page > 1:\n",
    "            if i==1:\n",
    "                elementID=driver.find_element_by_xpath('//*[@id=\"btnNext\"]')\n",
    "                elementID.click()\n",
    "                time.sleep(15)\n",
    "#'//*[@id=\"onlineregisteredproject\"]/tr['+str(i)+']/td[7]/a'\n",
    "        wait = WebDriverWait(driver,10)\n",
    "        try:\n",
    "            wait.until(EC.element_to_be_clickable((By.XPATH,'//*[@id=\"gridview\"]/div[1]/div/table/tbody/tr['+str(i)+']/td[5]/a' ))).click()\n",
    "        except TimeoutException:\n",
    "            pass\n",
    "        #elementID=driver.find_element_by_xpath('//*[@id=\"gridview\"]/div[1]/div/table/tbody/tr['+str(i)+']/td[5]/a')\n",
    "       # elementID.click()\n",
    "        time.sleep(10)\n",
    "        driver.switch_to.window(driver.window_handles[-1])\n",
    "        Project_approved.append(driver.page_source)\n",
    "        time.sleep(10)\n",
    "        Project_name=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[2]/div/div[2]').text\n",
    "        print(Project_name)\n",
    "        Project_status = driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[2]/div/div[4]').text\n",
    "        Approval_date=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[3]/div/div[2]').text\n",
    "        Proposed_date_completion=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[4]/div/div[2]').text\n",
    "        #Revise_pro_com=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[4]/div/div[4]').text\n",
    "        Project_type =driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[1]/div/div[4]').text\n",
    "        Letigation=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[1]/div/div[2]').text\n",
    "        Promoter=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[2]/div/div[2]').text\n",
    "        Sy_no=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[4]/div/div[2]').text\n",
    "        Plot_house_no=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[4]/div/div[4]').text\n",
    "        Total_area=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[5]/div/div[2]').text\n",
    "        Area_Afected_road_widen=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[5]/div/div[4]').text\n",
    "        Net_area=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[6]/div/div[2]').text\n",
    "        Total_building_unit=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[6]/div/div[4]').text\n",
    "        Proposed_building_unit=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[7]/div/div[2]').text\n",
    "        Approved_build_up_area=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[12]/div/div[2]').text\n",
    "        Mortgage_area=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[12]/div/div[3]/div[2]').text\n",
    "        State=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[15]/div/div[2]').text\n",
    "        District=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[15]/div/div[4]').text\n",
    "        Mandal=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[16]/div/div[2]').text\n",
    "        Village=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[16]/div/div[4]').text\n",
    "        Street=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[17]/div[1]/div[2]').text\n",
    "        Locality=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[17]/div[1]/div[4]').text\n",
    "        Pincode=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[7]/div/div[2]').text\n",
    "        Authority_name=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[1]/div/div[2]').text\n",
    "        Plan_approval_no=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[1]/div/div[4]').text\n",
    "        soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        TARGET_DIR = f'/home/anm/rera_telangana/ab/'\n",
    "\n",
    "        id_list = [\"DivExp\",\"DivAmenities\", \"DivBuilding\", \"DivProfessional\"]\n",
    "\n",
    "        #soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        #file = 1\n",
    "        # iterate over all tables\n",
    "        filepath = \"{}Project_{}.xlsx\".format(TARGET_DIR,file)\n",
    "        wb = openpyxl.Workbook()\n",
    "        wb.save(filepath)\n",
    "        print(filepath)\n",
    "\n",
    "        print(\"Created excel file Project_{}.xlsx\".format(file))\n",
    "\n",
    "        for il in range(len(id_list)):\n",
    "\n",
    "            table_topic_list = []\n",
    "            print(id_list[il])\n",
    "\n",
    "\n",
    "            table_header = soup.find(\"div\", id = id_list[il]).select(\"h2\")\n",
    "            #table.select(\"h2\")\n",
    "\n",
    "            if(len(table_header) > 0):\n",
    "                for j in range(len(table_header)):\n",
    "                    table_topic=table_header[j].text\n",
    "                    print(table_topic)\n",
    "                    table_topic_list.append(table_topic)\n",
    "            else: \n",
    "                print(\"No header\")\n",
    "                table_topic = 'NA'\n",
    "                table_topic_list.append(table_topic)\n",
    "\n",
    "\n",
    "            table_list = soup.find(\"div\", id = id_list[il]).select(\"table\")\n",
    "            #table.select(\"h2\")\n",
    "            #table_name=table_metaname[0].text\n",
    "            print(f\"[+] Found a total of {len(table_list)} tables.\")\n",
    "            if(len(table_list) > 0):\n",
    "\n",
    "                counter = 0\n",
    "\n",
    "                nested_table = []\n",
    "                in_tables = []\n",
    "\n",
    "                for t in table_list:\n",
    "                    nest = len(t.find_parents(\"table\"))\n",
    "                    if nest == 1:\n",
    "                        in_tables.append(t)\n",
    "                    nested_table.append(nest)\n",
    "\n",
    "\n",
    "                if all(v == 0 for v in nested_table):\n",
    "\n",
    "                    print(\"okay\")\n",
    "\n",
    "                    for num_table in range(len(table_list)):\n",
    "                        #try:\n",
    "                        # get the table headers\n",
    "                        headers = get_table_headers(table_list[num_table])\n",
    "                        # get all the rows of the table\n",
    "                        rows = get_table_rows(table_list[num_table])\n",
    "                        path = \"{}Project_{}.xlsx\".format(TARGET_DIR,file)\n",
    "                        book = load_workbook(path)\n",
    "                        writer = pd.ExcelWriter(path, engine = 'openpyxl')\n",
    "                        writer.book = book\n",
    "\n",
    "                        # save table as sheet\n",
    "                        table_name = table_topic_list[counter]\n",
    "                        counter = counter + 1\n",
    "                        print(f\"[+] Saving {table_name}\")\n",
    "                        print(headers)\n",
    "                        print(rows)\n",
    "                        save_as_csv(table_name, headers, rows, writer)\n",
    "\n",
    "                else:\n",
    "                    print(\"nested\")\n",
    "\n",
    "                    for num_table in range(len(in_tables)):\n",
    "\n",
    "                        if len(in_tables[num_table].find_parents(\"table\")) == 1:\n",
    "\n",
    "                            #try:\n",
    "                            # get the table headers\n",
    "                            headers = get_table_headers(in_tables[num_table])\n",
    "                            # get all the rows of the table\n",
    "                            rows = get_table_rows(in_tables[num_table])\n",
    "                            path = \"{}Project_{}.xlsx\".format(TARGET_DIR,file)\n",
    "                            book = load_workbook(path)\n",
    "                            writer = pd.ExcelWriter(path, engine = 'openpyxl')\n",
    "                            writer.book = book\n",
    "\n",
    "                            # save table as sheet\n",
    "                            table_name = table_topic_list[counter]\n",
    "                            #counter = counter + 1\n",
    "                            print(f\"[+] Saving {table_name}\")\n",
    "                            print(headers)\n",
    "                            print(rows)\n",
    "                            save_as_csv(table_name, headers, rows, writer)\n",
    "\n",
    "\n",
    "                    table = table_list[0]\n",
    "                    for tdcol in table.select('td[colspan]'):\n",
    "                        tdcol.parent.decompose()\n",
    "\n",
    "\n",
    "                    #try:\n",
    "                    # get the table headers\n",
    "                    headers = get_table_headers(table)\n",
    "                    # get all the rows of the table\n",
    "                    rows = get_table_rows(table)\n",
    "                    path = \"{}Project_{}.xlsx\".format(TARGET_DIR,file)\n",
    "                    book = load_workbook(path)\n",
    "                    writer = pd.ExcelWriter(path, engine = 'openpyxl')\n",
    "                    writer.book = book\n",
    "\n",
    "                    # save table as sheet\n",
    "                    table_name = table_topic_list[counter]\n",
    "                    #counter = counter + 1\n",
    "                    print(f\"[+] Saving {table_name}\")\n",
    "                    print(headers)\n",
    "                    print(rows)\n",
    "                    save_as_csv(table_name, headers, rows, writer)\n",
    "                #except:\n",
    "                    #print(\"fail\")\n",
    "                #print(table_name)\n",
    "\n",
    "        else: \n",
    "                counter = 0\n",
    "                print(\"No Table was found\")\n",
    "                table_name = table_topic_list[counter]\n",
    "                save_as_csv_dummy (writer, table_name)\n",
    "\n",
    "\n",
    "        file= file + 1\n",
    "            #table_metaname[0]\n",
    "\n",
    "        Project_details = [Project_name,Project_status,Approval_date,Proposed_date_completion,Project_type,\n",
    "                        Letigation,Promoter,Sy_no,Plot_house_no,Total_area,Area_Afected_road_widen,Net_area,Total_building_unit,\n",
    "                        Proposed_building_unit,Approved_build_up_area, Mortgage_area,State,District,Mandal,Village,Street,Locality,\n",
    "                           Pincode,Authority_name,Plan_approval_no]\n",
    "        Project_details_list.append(Project_details)\n",
    "\n",
    "        i=i+1\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "    \n",
    "Project_details_list_df = pd.DataFrame(Project_details_list)\n",
    "Project_details_list_df.to_csv(\"/home/anm/rera_telangana/rerate.csv\", index = False)\n",
    "print(\"Task Completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter File Number:1\n",
      "Enter Start Page:2\n",
      "Enter End Page:3\n",
      "\n",
      "Manbhum Around the Grove\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/anm/rera_telangana/ab/Project_1.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0c6b3cab1a3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{}Project_{}.xlsx\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTARGET_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mwb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenpyxl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWorkbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mwb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/openpyxl/workbook/workbook.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_only\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworksheets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_sheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0msave_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/openpyxl/writer/excel.py\u001b[0m in \u001b[0;36msave_workbook\u001b[0;34m(workbook, filename)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \"\"\"\n\u001b[0;32m--> 291\u001b[0;31m     \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZIP_DEFLATED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowZip64\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkbook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marchive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/anm/rera_telangana/ab/Project_1.xlsx'"
     ]
    }
   ],
   "source": [
    "file = int(input(\"Enter File Number:\"))\n",
    "i=1\n",
    "k=1\n",
    "page=1\n",
    "driver_call(url)\n",
    "Project_approved = []           \n",
    "Project_details = []\n",
    "Project_details_list = []\n",
    "for k in range(int(input(\"Enter Start Page:\")),int(input(\"Enter End Page:\"))):\n",
    "    elementID=driver.find_element_by_xpath('//*[@id=\"btnNext\"]')\n",
    "    elementID.click()\n",
    "\n",
    "while(i<12):\n",
    "    \n",
    "    print(\"\")\n",
    "    \n",
    "    \n",
    "    if i==11:\n",
    "\n",
    "        i=1\n",
    "        print(\"row\",i)\n",
    "        page = page + 1\n",
    "        \n",
    "        print(\"page\",page)\n",
    "        if page==218:\n",
    "            i=12\n",
    "\n",
    "    else:\n",
    "        \n",
    "        if page > 1:\n",
    "            if i==1:\n",
    "                elementID=driver.find_element_by_xpath('//*[@id=\"btnNext\"]')\n",
    "                elementID.click()\n",
    "                time.sleep(15)\n",
    "#'//*[@id=\"onlineregisteredproject\"]/tr['+str(i)+']/td[7]/a'\n",
    "        wait = WebDriverWait(driver,10)\n",
    "        try:\n",
    "            wait.until(EC.element_to_be_clickable((By.XPATH,'//*[@id=\"gridview\"]/div[1]/div/table/tbody/tr['+str(i)+']/td[5]/a' ))).click()\n",
    "        except TimeoutException:\n",
    "            pass\n",
    "        #elementID=driver.find_element_by_xpath('//*[@id=\"gridview\"]/div[1]/div/table/tbody/tr['+str(i)+']/td[5]/a')\n",
    "       # elementID.click()\n",
    "        time.sleep(10)\n",
    "        driver.switch_to.window(driver.window_handles[-1])\n",
    "        Project_approved.append(driver.page_source)\n",
    "        time.sleep(10)\n",
    "        Project_name=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[2]/div/div[2]').text\n",
    "        print(Project_name)\n",
    "        Project_status = driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[2]/div/div[4]').text\n",
    "        Approval_date=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[3]/div/div[2]').text\n",
    "        Proposed_date_completion=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[4]/div/div[2]').text\n",
    "        #Revise_pro_com=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[4]/div/div[4]').text\n",
    "        Project_type =driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[1]/div/div[4]').text\n",
    "        Letigation=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[1]/div/div[2]').text\n",
    "        Promoter=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[2]/div/div[2]').text\n",
    "        Sy_no=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[4]/div/div[2]').text\n",
    "        Plot_house_no=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[4]/div/div[4]').text\n",
    "        Total_area=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[5]/div/div[2]').text\n",
    "        Area_Afected_road_widen=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[5]/div/div[4]').text\n",
    "        Net_area=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[6]/div/div[2]').text\n",
    "        Total_building_unit=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[6]/div/div[4]').text\n",
    "        Proposed_building_unit=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[7]/div/div[2]').text\n",
    "        Approved_build_up_area=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[12]/div/div[2]').text\n",
    "        Mortgage_area=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[12]/div/div[3]/div[2]').text\n",
    "        State=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[15]/div/div[2]').text\n",
    "        District=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[15]/div/div[4]').text\n",
    "        Mandal=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[16]/div/div[2]').text\n",
    "        Village=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[16]/div/div[4]').text\n",
    "        Street=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[17]/div[1]/div[2]').text\n",
    "        Locality=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[6]/div[17]/div[1]/div[4]').text\n",
    "        Pincode=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[7]/div/div[2]').text\n",
    "        Authority_name=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[1]/div/div[2]').text\n",
    "        Plan_approval_no=driver.find_element_by_xpath('//*[@id=\"DivProject\"]/div/div[2]/div[1]/div/div[4]').text\n",
    "        soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        TARGET_DIR = f'/home/anm/rera_telangana/ab/'\n",
    "\n",
    "        id_list = [\"DivExp\",\"DivAmenities\", \"DivBuilding\", \"DivProfessional\"]\n",
    "\n",
    "        #soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        #file = 1\n",
    "        # iterate over all tables\n",
    "        filepath = \"{}Project_{}.xlsx\".format(TARGET_DIR,file)\n",
    "        wb = openpyxl.Workbook()\n",
    "        wb.save(filepath)\n",
    "        print(filepath)\n",
    "\n",
    "        print(\"Created excel file Project_{}.xlsx\".format(file))\n",
    "\n",
    "        for il in range(len(id_list)):\n",
    "\n",
    "            table_topic_list = []\n",
    "            print(id_list[il])\n",
    "\n",
    "\n",
    "            table_header = soup.find(\"div\", id = id_list[il]).select(\"h2\")\n",
    "            #table.select(\"h2\")\n",
    "\n",
    "            if(len(table_header) > 0):\n",
    "                for j in range(len(table_header)):\n",
    "                    table_topic=table_header[j].text\n",
    "                    print(table_topic)\n",
    "                    table_topic_list.append(table_topic)\n",
    "            else: \n",
    "                print(\"No header\")\n",
    "                table_topic = 'NA'\n",
    "                table_topic_list.append(table_topic)\n",
    "\n",
    "\n",
    "            table_list = soup.find(\"div\", id = id_list[il]).select(\"table\")\n",
    "            #table.select(\"h2\")\n",
    "            #table_name=table_metaname[0].text\n",
    "            print(f\"[+] Found a total of {len(table_list)} tables.\")\n",
    "            if(len(table_list) > 0):\n",
    "\n",
    "                counter = 0\n",
    "\n",
    "                nested_table = []\n",
    "                in_tables = []\n",
    "\n",
    "                for t in table_list:\n",
    "                    nest = len(t.find_parents(\"table\"))\n",
    "                    if nest == 1:\n",
    "                        in_tables.append(t)\n",
    "                    nested_table.append(nest)\n",
    "\n",
    "\n",
    "                if all(v == 0 for v in nested_table):\n",
    "\n",
    "                    print(\"okay\")\n",
    "\n",
    "                    for num_table in range(len(table_list)):\n",
    "                        #try:\n",
    "                        # get the table headers\n",
    "                        headers = get_table_headers(table_list[num_table])\n",
    "                        # get all the rows of the table\n",
    "                        rows = get_table_rows(table_list[num_table])\n",
    "                        path = \"{}Project_{}.xlsx\".format(TARGET_DIR,file)\n",
    "                        book = load_workbook(path)\n",
    "                        writer = pd.ExcelWriter(path, engine = 'openpyxl')\n",
    "                        writer.book = book\n",
    "\n",
    "                        # save table as sheet\n",
    "                        table_name = table_topic_list[counter]\n",
    "                        counter = counter + 1\n",
    "                        print(f\"[+] Saving {table_name}\")\n",
    "                        print(headers)\n",
    "                        print(rows)\n",
    "                        save_as_csv(table_name, headers, rows, writer)\n",
    "\n",
    "                else:\n",
    "                    print(\"nested\")\n",
    "\n",
    "                    for num_table in range(len(in_tables)):\n",
    "\n",
    "                        if len(in_tables[num_table].find_parents(\"table\")) == 1:\n",
    "\n",
    "                            #try:\n",
    "                            # get the table headers\n",
    "                            headers = get_table_headers(in_tables[num_table])\n",
    "                            # get all the rows of the table\n",
    "                            rows = get_table_rows(in_tables[num_table])\n",
    "                            path = \"{}Project_{}.xlsx\".format(TARGET_DIR,file)\n",
    "                            book = load_workbook(path)\n",
    "                            writer = pd.ExcelWriter(path, engine = 'openpyxl')\n",
    "                            writer.book = book\n",
    "\n",
    "                            # save table as sheet\n",
    "                            table_name = table_topic_list[counter]\n",
    "                            #counter = counter + 1\n",
    "                            print(f\"[+] Saving {table_name}\")\n",
    "                            print(headers)\n",
    "                            print(rows)\n",
    "                            save_as_csv(table_name, headers, rows, writer)\n",
    "\n",
    "\n",
    "                    table = table_list[0]\n",
    "                    for tdcol in table.select('td[colspan]'):\n",
    "                        tdcol.parent.decompose()\n",
    "\n",
    "\n",
    "                    #try:\n",
    "                    # get the table headers\n",
    "                    headers = get_table_headers(table)\n",
    "                    # get all the rows of the table\n",
    "                    rows = get_table_rows(table)\n",
    "                    path = \"{}Project_{}.xlsx\".format(TARGET_DIR,file)\n",
    "                    book = load_workbook(path)\n",
    "                    writer = pd.ExcelWriter(path, engine = 'openpyxl')\n",
    "                    writer.book = book\n",
    "\n",
    "                    # save table as sheet\n",
    "                    table_name = table_topic_list[counter]\n",
    "                    #counter = counter + 1\n",
    "                    print(f\"[+] Saving {table_name}\")\n",
    "                    print(headers)\n",
    "                    print(rows)\n",
    "                    save_as_csv(table_name, headers, rows, writer)\n",
    "                #except:\n",
    "                    #print(\"fail\")\n",
    "                #print(table_name)\n",
    "\n",
    "        else: \n",
    "                counter = 0\n",
    "                print(\"No Table was found\")\n",
    "                table_name = table_topic_list[counter]\n",
    "                save_as_csv_dummy (writer, table_name)\n",
    "\n",
    "\n",
    "        file= file + 1\n",
    "            #table_metaname[0]\n",
    "\n",
    "        Project_details = [Project_name,Project_status,Approval_date,Proposed_date_completion,Project_type,\n",
    "                        Letigation,Promoter,Sy_no,Plot_house_no,Total_area,Area_Afected_road_widen,Net_area,Total_building_unit,\n",
    "                        Proposed_building_unit,Approved_build_up_area, Mortgage_area,State,District,Mandal,Village,Street,Locality,\n",
    "                           Pincode,Authority_name,Plan_approval_no]\n",
    "        Project_details_list.append(Project_details)\n",
    "\n",
    "        i=i+1\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "    \n",
    "Project_details_list_df = pd.DataFrame(Project_details_list)\n",
    "Project_details_list_df.to_csv(\"/home/anm/rera_telangana/ab.csv\", index = False)\n",
    "print(\"Task Completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
